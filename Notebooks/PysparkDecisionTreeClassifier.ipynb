{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "62F-E4teYIqa"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession\\\r\n",
        "    .builder\\\r\n",
        "    .appName(\"Heart Failure Predictions\")\\\r\n",
        "    .getOrCreate()\r\n",
        "\r\n",
        "df = spark.read\\\r\n",
        "    .option(\"header\", True)\\\r\n",
        "    .csv(\"heart_failure.csv\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GngRS0c4YcNC"
      },
      "source": [
        "numerical_features = [\r\n",
        "    \"anaemia\",\r\n",
        "    \"diabetes\",\r\n",
        "    \"high_blood_pressure\",\r\n",
        "    \"sex\",\r\n",
        "    \"smoking\"\r\n",
        "]\r\n",
        "categorical_features = [\r\n",
        "    \"age\",\r\n",
        "    \"creatinine_phosphokinase\",\r\n",
        "    \"ejection_fraction\",\r\n",
        "    \"platelets\",\r\n",
        "    \"serum_creatinine\",\r\n",
        "    \"serum_sodium\",\r\n",
        "    \"time\"\r\n",
        "]"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t43-vJY2ZIeq"
      },
      "source": [
        "from pyspark.sql.types import DoubleType, BooleanType, IntegerType\r\n",
        "import pyspark.sql.functions as f\r\n",
        "\r\n",
        "df = df.withColumn(\"age\", f.col(\"age\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"creatinine_phosphokinase\", f.col(\"creatinine_phosphokinase\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"ejection_fraction\", f.col(\"ejection_fraction\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"high_blood_pressure\", f.col(\"high_blood_pressure\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"platelets\", f.col(\"platelets\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"serum_creatinine\", f.col(\"serum_creatinine\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"serum_sodium\", f.col(\"serum_sodium\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"DEATH_EVENT\", f.col(\"DEATH_EVENT\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"anaemia\", f.col(\"anaemia\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"diabetes\", f.col(\"diabetes\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"high_blood_pressure\", f.col(\"high_blood_pressure\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"sex\", f.col(\"sex\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"smoking\", f.col(\"smoking\").cast(IntegerType()))\\\r\n",
        "  .withColumnRenamed(\"DEATH_EVENT\", \"label\")\\\r\n",
        "  .drop(\"time\")"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aoZCfvyubQ6f"
      },
      "source": [
        "from pyspark.sql import Window\r\n",
        "import pyspark.sql.functions as f\r\n",
        "\r\n",
        "window = Window.partitionBy(\"label\").orderBy(\"serum_creatinine\")\r\n",
        "udf = f.udf(lambda x: x % 5 == 0, BooleanType())"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EiPUgEubvPM"
      },
      "source": [
        "df = df.withColumn(\"_test_set\", f.row_number().over(window))\\\r\n",
        "  .withColumn(\"_test_set\", udf(f.col(\"_test_set\")))"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3ZdIPNDeomB"
      },
      "source": [
        "test = df.where(df[\"_test_set\"] == True)\r\n",
        "test = test.drop(\"_test_set\")\r\n",
        "train = df.where(df[\"_test_set\"] == False)\r\n",
        "train = train.drop(\"_test_set\")"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7jUpbnJ_fZ0K"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, VectorIndexer\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "\r\n",
        "assembler = VectorAssembler(inputCols = train.columns[:-1], \r\n",
        "                            outputCol = \"vec\")\r\n",
        "indexer = VectorIndexer(inputCol = \"vec\", \r\n",
        "                        outputCol = \"features\", \r\n",
        "                        maxCategories = 4)\r\n",
        "pipeline = Pipeline(stages = [assembler, indexer])"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2LlHW0bfh_b"
      },
      "source": [
        "pipeline = pipeline.fit(train)\r\n",
        "train = pipeline.transform(train)\r\n",
        "test = pipeline.transform(test)"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HCFmlbugdgu"
      },
      "source": [
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\r\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "from pyspark.ml.classification import DecisionTreeClassifier\r\n",
        "\r\n",
        "dt = DecisionTreeClassifier()\r\n",
        "\r\n",
        "paramGrid = ParamGridBuilder()\\\r\n",
        "  .addGrid(dt.maxDepth, [2, 3, 4])\\\r\n",
        "  .addGrid(dt.maxBins, [10, 15, 32])\\\r\n",
        "  .build()\r\n",
        "\r\n",
        "crossval = CrossValidator(estimator = dt,\r\n",
        "                          estimatorParamMaps = paramGrid,\r\n",
        "                          evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderPR\"),\r\n",
        "                          numFolds = 3)\r\n",
        "cvModel = crossval.fit(train)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ScTTB5ftjWiB"
      },
      "source": [
        "bestModel = cvModel.bestModel\r\n",
        "test = bestModel.transform(test)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uss6rA-goB8",
        "outputId": "d89cd899-e5ab-4655-eb1e-35aef45093c2"
      },
      "source": [
        "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderPR\")\r\n",
        "evaluator.evaluate(test)"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1994903189360176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    }
  ]
}