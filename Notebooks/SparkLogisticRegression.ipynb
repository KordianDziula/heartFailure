{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "from pyspark.sql.types import DoubleType, BooleanType\n",
    "from pyspark.sql import Window\n",
    "\n",
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .appName(\"Heart Failure Predictions\")\\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .option(\"header\", True)\\\n",
    "    .csv(\"heart_failure.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    \"age\",\n",
    "    \"ejection_fraction\",\n",
    "    \"serum_creatinine\",\n",
    "    \"serum_sodium\",\n",
    "    \"DEATH_EVENT\"\n",
    "]\n",
    "df = df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df\\\n",
    "    .withColumn(\"age\", f.col(\"age\").cast(DoubleType()))\\\n",
    "    .withColumn(\"ejection_fraction\", f.col(\"ejection_fraction\").cast(DoubleType()))\\\n",
    "    .withColumn(\"serum_creatinine\", f.col(\"serum_creatinine\").cast(DoubleType()))\\\n",
    "    .withColumn(\"serum_sodium\", f.col(\"serum_sodium\").cast(DoubleType()))\\\n",
    "    .withColumn(\"DEATH_EVENT\", f.col(\"DEATH_EVENT\").cast(DoubleType()))\\\n",
    "    .withColumnRenamed(\"DEATH_EVENT\", \"label\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = Window.partitionBy(\"label\").orderBy(\"serum_creatinine\")\n",
    "udf = f.udf(lambda x: x % 5 == 0, BooleanType())\n",
    "\n",
    "df = df\\\n",
    "    .withColumn(\"test_set\", f.row_number().over(window))\\\n",
    "    .withColumn(\"test_set\", udf(f.col(\"test_set\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+-----------------+----------------+------------+-----+--------+\n",
      "| age|ejection_fraction|serum_creatinine|serum_sodium|label|test_set|\n",
      "+----+-----------------+----------------+------------+-----+--------+\n",
      "|50.0|             30.0|             0.5|       139.0|  0.0|   false|\n",
      "|60.0|             40.0|             0.6|       138.0|  0.0|   false|\n",
      "|75.0|             38.0|             0.6|       131.0|  0.0|   false|\n",
      "|51.0|             50.0|             0.7|       140.0|  0.0|   false|\n",
      "|44.0|             40.0|             0.7|       139.0|  0.0|    true|\n",
      "|58.0|             38.0|             0.7|       142.0|  0.0|   false|\n",
      "|60.0|             60.0|             0.7|       136.0|  0.0|   false|\n",
      "|61.0|             30.0|             0.7|       136.0|  0.0|   false|\n",
      "|53.0|             60.0|             0.7|       138.0|  0.0|   false|\n",
      "|50.0|             30.0|             0.7|       141.0|  0.0|    true|\n",
      "+----+-----------------+----------------+------------+-----+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df.where(df[\"test_set\"] == True)\n",
    "test = test.drop(\"test_set\")\n",
    "\n",
    "train = df.where(df[\"test_set\"] == False)\n",
    "train = train.drop(\"test_set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler, MinMaxScaler\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.classification import LogisticRegression\n",
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler = VectorAssembler(\n",
    "    inputCols = [\"age\", \"ejection_fraction\", \"serum_creatinine\", \"serum_sodium\"], \n",
    "    outputCol = \"vec\"\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol = \"vec\", \n",
    "    outputCol = \"features\"\n",
    ")\n",
    "pipeline = Pipeline(stages = [\n",
    "    assembler,\n",
    "    scaler\n",
    "])\n",
    "\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = pipeline.fit(train)\n",
    "train = pipeline.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paramGrid = ParamGridBuilder()\\\n",
    "    .addGrid(lr.regParam, [0.1, 0.01])\\\n",
    "    .addGrid(lr.maxIter, [50, 100])\\\n",
    "    .build()\n",
    "#.addGrid(lr.elasticNetParam, [0.5, 0.8])\\\n",
    "crossval = CrossValidator(estimator =lr,\n",
    "                          estimatorParamMaps = paramGrid,\n",
    "                          evaluator = BinaryClassificationEvaluator(),\n",
    "                          numFolds = 3)\n",
    "crossval.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.mllib.evaluation import BinaryClassificationMetrics\n",
    "\n",
    "test = crossval.transform(test)\n",
    "metrics = BinaryClassificationMetrics(test[[\"prediction\", \"label\"]].rdd)\n",
    "print(metrics.areaUnderPR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
