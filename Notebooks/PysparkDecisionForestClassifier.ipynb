{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled12.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJQfi7rLt-y1"
      },
      "source": [
        "from pyspark.sql import SparkSession\r\n",
        "\r\n",
        "spark = SparkSession\\\r\n",
        "    .builder\\\r\n",
        "    .appName(\"Heart Failure Predictions\")\\\r\n",
        "    .getOrCreate()\r\n",
        "\r\n",
        "df = spark.read\\\r\n",
        "    .option(\"header\", True)\\\r\n",
        "    .csv(\"heart_failure.csv\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TRccA-wuyJI"
      },
      "source": [
        "from pyspark.sql.types import DoubleType, BooleanType, IntegerType\r\n",
        "import pyspark.sql.functions as f\r\n",
        "\r\n",
        "df = df.withColumn(\"age\", f.col(\"age\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"creatinine_phosphokinase\", f.col(\"creatinine_phosphokinase\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"ejection_fraction\", f.col(\"ejection_fraction\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"high_blood_pressure\", f.col(\"high_blood_pressure\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"platelets\", f.col(\"platelets\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"serum_creatinine\", f.col(\"serum_creatinine\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"serum_sodium\", f.col(\"serum_sodium\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"DEATH_EVENT\", f.col(\"DEATH_EVENT\").cast(DoubleType()))\\\r\n",
        "  .withColumn(\"anaemia\", f.col(\"anaemia\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"diabetes\", f.col(\"diabetes\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"high_blood_pressure\", f.col(\"high_blood_pressure\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"sex\", f.col(\"sex\").cast(IntegerType()))\\\r\n",
        "  .withColumn(\"smoking\", f.col(\"smoking\").cast(IntegerType()))\\\r\n",
        "  .withColumnRenamed(\"DEATH_EVENT\", \"label\")\\\r\n",
        "  .drop(\"time\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPX4Ruuau_9-"
      },
      "source": [
        "from pyspark.sql import Window\r\n",
        "import pyspark.sql.functions as f\r\n",
        "\r\n",
        "window = Window.partitionBy(\"label\").orderBy(\"serum_creatinine\")\r\n",
        "udf = f.udf(lambda x: x % 5 == 0, BooleanType())"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LU-ezh5fvBNq"
      },
      "source": [
        "df = df.withColumn(\"_test_set\", f.row_number().over(window))\\\r\n",
        "  .withColumn(\"_test_set\", udf(f.col(\"_test_set\")))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIfpACZevCSv"
      },
      "source": [
        "test = df.where(df[\"_test_set\"] == True)\r\n",
        "test = test.drop(\"_test_set\")\r\n",
        "train = df.where(df[\"_test_set\"] == False)\r\n",
        "train = train.drop(\"_test_set\")"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_aiq6UtyvDOE"
      },
      "source": [
        "from pyspark.ml.feature import VectorAssembler, VectorIndexer\r\n",
        "from pyspark.ml import Pipeline\r\n",
        "\r\n",
        "assembler = VectorAssembler(inputCols = train.columns[:-1], \r\n",
        "                            outputCol = \"vec\")\r\n",
        "indexer = VectorIndexer(inputCol = \"vec\", \r\n",
        "                        outputCol = \"features\", \r\n",
        "                        maxCategories = 4)\r\n",
        "pipeline = Pipeline(stages = [assembler, indexer])"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSvzRv9MvEjr"
      },
      "source": [
        "pipeline = pipeline.fit(train)\r\n",
        "train = pipeline.transform(train)\r\n",
        "test = pipeline.transform(test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUBufh6EvF_I"
      },
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\r\n",
        "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\r\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\r\n",
        "\r\n",
        "rf = RandomForestClassifier()\r\n",
        "\r\n",
        "paramGrid = ParamGridBuilder()\\\r\n",
        "  .addGrid(rf.maxDepth, [2, 4, 6])\\\r\n",
        "  .addGrid(rf.numTrees, [10, 20, 30])\\\r\n",
        "  .build()\r\n",
        "\r\n",
        "crossval = CrossValidator(estimator = rf,\r\n",
        "                          estimatorParamMaps = paramGrid,\r\n",
        "                          evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderPR\"),\r\n",
        "                          numFolds = 3)\r\n",
        "cvModel = crossval.fit(train)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-yUScuM0fVo"
      },
      "source": [
        "bestModel = cvModel.bestModel\r\n",
        "test = bestModel.transform(test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_sCq6DWU0KZi",
        "outputId": "8e290a29-db70-4a3f-e148-00161b60c007"
      },
      "source": [
        "evaluator = BinaryClassificationEvaluator(metricName = \"areaUnderPR\")\r\n",
        "evaluator.evaluate(test)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7588977319143877"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    }
  ]
}